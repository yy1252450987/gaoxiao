{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['video_create_log.txt', 'user_activity_log.txt', 'app_launch_log.txt', 'user_register_log.txt']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# Load dataset\nregister_df = pd.read_table('../input/user_register_log.txt',header=None, sep='\\t',\n                            names=['user_id','register_day','register_type','device_type'])\nlaunch_df = pd.read_table('../input/app_launch_log.txt', names=['user_id','launch_day'],header=None, sep='\\t')\nvideo_df = pd.read_table('../input/video_create_log.txt', names=['user_id','create_day'],header=None, sep='\\t')\nactivity_df = pd.read_table('../input/user_activity_log.txt', header=None, sep='\\t',\n                            names=['user_id','activity_day','page','video_id','author_id','action_type'])",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0e460e30b75ce8f99e20af936a7147fff6f1c98e",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# train dataset\n## train x\ntr_time = 24\ntr_register_df = register_df[register_df.register_day<=tr_time]\ntr_x_df = tr_register_df\n## train y\ntr_launch_uid = launch_df[launch_df.launch_day>tr_time].user_id.unique()\ntr_video_uid = video_df[video_df.create_day>tr_time].user_id.unique()\ntr_activity_uid = activity_df[activity_df.activity_day>tr_time].user_id.unique()\ntr_y = tr_register_df.user_id.map(lambda x: x in tr_launch_uid or x in tr_activity_uid or x in tr_video_uid ).map({False: 0, True:1})",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "97831e2c090f5aed6618a3ef86738983b156a683"
      },
      "cell_type": "code",
      "source": "# register\n# register type --> (0,1,2,3)\ntr_x_df[tr_x_df.register_type>=3]['register_type'] = 3\n# register: device type --> (0,1,2,3)\ndevice_type_count = tr_x_df['device_type'].value_counts()\ndef device_map(x):\n    if(device_type_count[x]>1500):\n        return 0\n    elif(device_type_count[x]>1000):\n        return 1\n    elif(device_type_count[x]>500):\n        return 2\n    else:\n        return 3\n\ntr_device_type = tr_x_df['device_type'].map(device_map)\ntr_x_df['device_pop_type'] = tr_device_type",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  This is separate from the ipykernel package so we can avoid doing imports until\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6956ce93d8b1e1ecfafed8488e2c89947809857c"
      },
      "cell_type": "code",
      "source": "# launch\ntr_launch_df = launch_df[launch_df.launch_day<=tr_time]\n# launch_bool\ntr_launch_uid = tr_launch_df.user_id.unique()\ntr_x_df['launch_bool'] = tr_register_df.user_id.map(lambda x: x in tr_launch_uid).map({False: 0, True:1})\n# launch num (ununique)\ntr_launch_df_rmdup = tr_launch_df.drop_duplicates()\ntr_launch_num_df = tr_launch_df.groupby('user_id').count().reset_index().rename(columns={'launch_day': 'launch_num'})\n# launch count(unique)\ntr_launch_count_df = tr_launch_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'launch_day': 'launch_count'})\n# launch ratio\ntr_launch_ratio_df = pd.merge(tr_register_df[['user_id', 'register_day']],tr_launch_count_df, how='left', on='user_id' )\ntr_x_df['launch_ratio'] = tr_launch_ratio_df.launch_count/(tr_time-tr_launch_ratio_df.register_day+1)\n# launch first day interval\ntr_launch_firstday_df = tr_launch_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'launch_day': 'launch_firstday_interval'})\ntr_launch_firstday_interval = tr_launch_firstday_df['launch_firstday_interval']-tr_register_df[tr_x_df['launch_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\ntr_launch_firstday_interval_df = pd.concat([tr_launch_firstday_df.user_id, tr_launch_firstday_interval], axis=1)\ntr_launch_firstday_interval_df.columns=['user_id', 'launch_firstday_interval']\n# launch last day interval\ntr_launch_lastday_df = tr_launch_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'launch_day': 'launch_lastday_interval'})\ntr_launch_lastday_interval = tr_time-tr_launch_lastday_df['launch_lastday_interval']\ntr_launch_lastday_interval_df = pd.concat([tr_launch_lastday_df.user_id, tr_launch_lastday_interval], axis=1)\n# launch interval day(max)\ntr_launch_df_sort = tr_launch_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('launch_day', ascending=True)).reset_index(drop=True)\ntr_launch_interval_df = pd.concat([tr_launch_df_sort['user_id'], tr_launch_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'launch_day': 'launch_interval_day'})",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  del sys.path[0]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14eefe64fd3b42a4f2ad356cd14cede8f0c43b1d",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def fillna_tr_launch_interval(df):\n    new_df = df\n    for idx, row in df.iterrows():\n        if(pd.isna(row.launch_interval_day)):\n            #print(tr_launch_firstday_df[tr_launch_firstday_df.user_id==row.user_id])\n            #print(tr_launch_lastday_df[tr_launch_lastday_df.user_id==row.user_id])\n            new_df.iloc[idx, 1] = max(int(tr_launch_firstday_df[tr_launch_firstday_df.user_id==row.user_id].launch_firstday_interval),\n                                      int(tr_launch_lastday_df[tr_launch_lastday_df.user_id==row.user_id].launch_lastday_interval))\n    return new_df\ntr_launch_interval_df = fillna_tr_launch_interval(tr_launch_interval_df)",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e3834891fd1a72e17297be08c167d6477a4dbdc2"
      },
      "cell_type": "code",
      "source": "# video \ntr_video_df = video_df[video_df.create_day<=tr_time]\n# video bool\ntr_video_uid = tr_video_df.user_id.unique()\ntr_x_df['create_bool']= tr_register_df.user_id.map(lambda x: x in tr_video_uid).map({False: 0, True:1})\n# video num (ununique)\ntr_video_df_rmdup = tr_video_df.drop_duplicates()\ntr_video_num_df = tr_video_df.groupby('user_id').count().reset_index().rename(columns={'create_day': 'create_num'})\n# video count (unique)\ntr_video_count_df = tr_video_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'create_day': 'create_count'})\n# video ratio \ntr_video_ratio_df = pd.merge(tr_register_df[['user_id', 'register_day']],tr_video_count_df, how='left', on='user_id' )\ntr_x_df['create_ratio'] = tr_video_ratio_df.create_count/(tr_time-tr_video_ratio_df.register_day+1)\n# video first day interval\ntr_video_firstday_df = tr_video_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'create_day': 'create_firstday_interval'})\ntr_video_firstday_interval = tr_video_firstday_df['create_firstday_interval']-tr_register_df[tr_x_df['create_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\ntr_video_firstday_interval_df = pd.concat([tr_video_firstday_df.user_id, tr_video_firstday_interval], axis=1)\ntr_video_firstday_interval_df.columns = ['user_id', 'create_firstday_interval']\n# video last day interval\ntr_video_lastday_df = tr_video_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'create_day': 'create_lastday_interval'})\ntr_video_lastday_interval = tr_time-tr_video_lastday_df['create_lastday_interval']\ntr_video_lastday_interval_df = pd.concat([tr_video_lastday_df.user_id, tr_video_lastday_interval], axis=1)\n# video interval day (max)\ntr_video_df_sort = tr_video_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('create_day', ascending=True)).reset_index(drop=True)\ntr_video_interval_df = pd.concat([tr_video_df_sort['user_id'], tr_video_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'create_day': 'create_interval_day'})",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  del sys.path[0]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "964c5b630f8b894071189e86d0f36e89966feff4",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def fillna_tr_video_interval(df):\n    new_df = df\n    for idx, row in df.iterrows():\n        if(pd.isna(row.create_interval_day)):\n            new_df.iloc[idx, 1] = max(int(tr_video_firstday_df[tr_video_firstday_df.user_id==row.user_id].create_firstday_interval),\n                                      int(tr_video_lastday_df[tr_video_lastday_df.user_id==row.user_id].create_lastday_interval))\n    return new_df\ntr_video_interval_df = fillna_tr_video_interval(tr_video_interval_df)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c876eaad3fba00ce44662668989d87ad91ea20d8"
      },
      "cell_type": "code",
      "source": "# acitivity \ntr_activity_df = activity_df[activity_df.activity_day<=tr_time]\n# activity bool\ntr_activity_uid = tr_activity_df.user_id.unique()\ntr_x_df['activity_bool']= tr_register_df.user_id.apply(lambda x: x in tr_activity_uid).map({False: 0, True:1})\n# acitivity num(ununique)\ntr_activity_df_rmdup = tr_activity_df[['user_id','activity_day']].drop_duplicates()\ntr_activity_num_df = tr_activity_df[['user_id','activity_day']].groupby('user_id').count().reset_index().rename(columns={'activity_day': 'activity_num'})\n# acitivity count(unique)\ntr_activity_count_df = tr_activity_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'activity_day': 'activity_count'})\n# activity ratio \ntr_activity_ratio_df = pd.merge(tr_register_df[['user_id', 'register_day']],tr_activity_count_df, how='left', on='user_id' )\ntr_x_df['activity_ratio'] = tr_activity_ratio_df.activity_count/(tr_time-tr_activity_ratio_df.register_day+1)\n# activity first day interval\ntr_activity_firstday_df = tr_activity_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'activity_day': 'activity_firstday_interval'})\ntr_activity_firstday_interval = tr_activity_firstday_df['activity_firstday_interval']-tr_register_df[tr_x_df['activity_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\ntr_activity_firstday_interval_df = pd.concat([tr_activity_firstday_df.user_id, tr_activity_firstday_interval], axis=1)\ntr_activity_firstday_interval_df.columns = ['user_id', 'activity_firstday_interval']\n# activity last day interval\ntr_activity_lastday_df = tr_activity_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'activity_day': 'activity_lastday_interval'})\ntr_activity_lastday_interval = tr_time-tr_activity_lastday_df['activity_lastday_interval']\ntr_activity_lastday_interval_df = pd.concat([tr_activity_lastday_df.user_id, tr_activity_lastday_interval], axis=1)\n# activity interval day (max)\ntr_activity_df_sort = tr_activity_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('activity_day', ascending=True)).reset_index(drop=True)\ntr_activity_interval_df = pd.concat([tr_activity_df_sort['user_id'], tr_activity_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'activity_day': 'activity_interval_day'})",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  del sys.path[0]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e6239dcc1c19773a140c9b7c20115572c4326a1",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def fillna_tr_activity_interval(df):\n    new_df = df\n    for idx, row in df.iterrows():\n        if(pd.isna(row.activity_interval_day)):\n            new_df.iloc[idx, 1] = max(int(tr_activity_firstday_df[tr_activity_firstday_df.user_id==row.user_id].activity_firstday_interval),\n                                      int(tr_activity_lastday_df[tr_activity_lastday_df.user_id==row.user_id].activity_lastday_interval))\n    return new_df\ntr_activity_interval_df = fillna_tr_activity_interval(tr_activity_interval_df)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f987f693a01e2569cee9eee9e8525c9b6fa7e52e"
      },
      "cell_type": "code",
      "source": "'''\ntr_activity_df = activity_df[activity_df.activity_day<=tr_time]\n# activity most page & activity action type\ndef count_tr_activity_most_page_actiontype(df):\n    mostpage_list = []\n    mostactiontype_list = []\n    for idx, uid in enumerate(df.user_id.unique()):\n        #print(df[df.user_id==uid]['page'].value_counts())\n        mostpage = df[df.user_id==uid]['page'].value_counts().idxmax()\n        mostactiontype = df[df.user_id==uid]['action_type'].value_counts().idxmax()\n        mostpage_list.append(mostpage)\n        mostactiontype_list.append(mostactiontype)\n    new_df = pd.DataFrame({'user_id':tr_activity_uid,'activity_most_page':mostpage_list, 'activity_most_action_type':mostactiontype_list})\n    return new_df\ncount_tr_activity_most_page_actiontype(tr_activity_df[['user_id','page','action_type']])\n# activity videos & activity author_id\ntr_activity_df[['user_id','video_id']].groupby('user_id').value_counts()\ntr_activity_df[['user_id','author_id']].groupby('user_id').value_counts()\n'''",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "\"\\ntr_activity_df = activity_df[activity_df.activity_day<=tr_time]\\n# activity most page & activity action type\\ndef count_tr_activity_most_page_actiontype(df):\\n    mostpage_list = []\\n    mostactiontype_list = []\\n    for idx, uid in enumerate(df.user_id.unique()):\\n        #print(df[df.user_id==uid]['page'].value_counts())\\n        mostpage = df[df.user_id==uid]['page'].value_counts().idxmax()\\n        mostactiontype = df[df.user_id==uid]['action_type'].value_counts().idxmax()\\n        mostpage_list.append(mostpage)\\n        mostactiontype_list.append(mostactiontype)\\n    new_df = pd.DataFrame({'user_id':tr_activity_uid,'activity_most_page':mostpage_list, 'activity_most_action_type':mostactiontype_list})\\n    return new_df\\ncount_tr_activity_most_page_actiontype(tr_activity_df[['user_id','page','action_type']])\\n# activity videos & activity author_id\\ntr_activity_df[['user_id','video_id']].groupby('user_id').value_counts()\\ntr_activity_df[['user_id','author_id']].groupby('user_id').value_counts()\\n\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fdc8f4067a27b418db6d816a487ebb0973b36142",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# merge register, video, activity\n\ntr_x_df = pd.merge(tr_x_df, tr_launch_num_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_launch_count_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_launch_firstday_interval_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_launch_lastday_interval_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_launch_interval_df, how='left', on='user_id')\n\ntr_x_df = pd.merge(tr_x_df, tr_video_num_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_video_count_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_video_firstday_interval_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_video_lastday_interval_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_video_interval_df, how='left', on='user_id')\n\ntr_x_df = pd.merge(tr_x_df, tr_activity_num_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_activity_count_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_activity_firstday_interval_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_activity_lastday_interval_df, how='left', on='user_id')\ntr_x_df = pd.merge(tr_x_df, tr_activity_interval_df, how='left', on='user_id')",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5f7a5839d516b1b2f9ae74acff82ee4b96662d2c"
      },
      "cell_type": "code",
      "source": "tr_x_df[['launch_firstday_interval', 'launch_lastday_interval', 'launch_interval_day',]].fillna(tr_time, inplace=True)\ntr_x_df[['create_firstday_interval', 'create_lastday_interval', 'create_interval_day',]].fillna(tr_time, inplace=True)\ntr_x_df[['activity_firstday_interval', 'activity_lastday_interval', 'activity_interval_day']].fillna(tr_time, inplace=True)\ntr_x_df.fillna(0, inplace=True)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3035: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  downcast=downcast, **kwargs)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "39b6a40441ad58cea9a2a18b88e72b696057cb6f"
      },
      "cell_type": "code",
      "source": "tr_x_df.head()",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "   user_id  register_day  register_type  device_type  device_pop_type  \\\n0   744025             1              1          283                3   \n1  1270299             1              1          259                3   \n2   571220             1              1            2                1   \n3  1308501             1              0           23                3   \n4   745554             1              2            0                0   \n\n   launch_bool  launch_ratio  create_bool  create_ratio  activity_bool  \\\n0            1      0.125000            0           0.0              1   \n1            1      0.083333            0           0.0              1   \n2            1      0.250000            0           0.0              1   \n3            1      0.541667            0           0.0              1   \n4            1      0.416667            0           0.0              1   \n\n         ...          register_type_6  register_type_7  register_type_8  \\\n0        ...                        0                0                0   \n1        ...                        0                0                0   \n2        ...                        0                0                0   \n3        ...                        0                0                0   \n4        ...                        0                0                0   \n\n   register_type_9  register_type_10  register_type_11  device_pop_type_0  \\\n0                0                 0                 0                  0   \n1                0                 0                 0                  0   \n2                0                 0                 0                  0   \n3                0                 0                 0                  0   \n4                0                 0                 0                  1   \n\n   device_pop_type_1  device_pop_type_2  device_pop_type_3  \n0                  0                  0                  1  \n1                  0                  0                  1  \n2                  1                  0                  0  \n3                  0                  0                  1  \n4                  0                  0                  0  \n\n[5 rows x 42 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>register_day</th>\n      <th>register_type</th>\n      <th>device_type</th>\n      <th>device_pop_type</th>\n      <th>launch_bool</th>\n      <th>launch_ratio</th>\n      <th>create_bool</th>\n      <th>create_ratio</th>\n      <th>activity_bool</th>\n      <th>...</th>\n      <th>register_type_6</th>\n      <th>register_type_7</th>\n      <th>register_type_8</th>\n      <th>register_type_9</th>\n      <th>register_type_10</th>\n      <th>register_type_11</th>\n      <th>device_pop_type_0</th>\n      <th>device_pop_type_1</th>\n      <th>device_pop_type_2</th>\n      <th>device_pop_type_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>744025</td>\n      <td>1</td>\n      <td>1</td>\n      <td>283</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.125000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1270299</td>\n      <td>1</td>\n      <td>1</td>\n      <td>259</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.083333</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>571220</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0.250000</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1308501</td>\n      <td>1</td>\n      <td>0</td>\n      <td>23</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.541667</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>745554</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.416667</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 42 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "578519569a438f0141bbe66d14614e2bfb9fc85d"
      },
      "cell_type": "code",
      "source": "# fill null value with 0 , get_dummie and drop columns\n#launch interval day (null value)\ntr_x_df = pd.concat([tr_x_df, pd.get_dummies(tr_x_df['register_type'], prefix='register_type')], axis=1)\ntr_x_df = pd.concat([tr_x_df, pd.get_dummies(tr_x_df['device_pop_type'], prefix='device_pop_type')], axis=1)\n#tr_x_df = pd.concat([tr_x_df, pd.get_dummies(tr_x_df['device_pop_type'], prefix='device_pop_type')], axis=1)\ntr_x_df = tr_x_df.drop(['user_id', 'device_type', 'device_pop_type','register_type'], axis=1)\ntr_x_df.head()",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "labels ['create_lastday' 'activity_lastday'] not contained in axis",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-06f9303ed589>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtr_x_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_x_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_x_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device_pop_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'device_pop_type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#tr_x_df = pd.concat([tr_x_df, pd.get_dummies(tr_x_df['device_pop_type'], prefix='device_pop_type')], axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtr_x_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtr_x_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'device_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'device_pop_type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'register_type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'create_lastday'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activity_lastday'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtr_x_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: labels ['create_lastday' 'activity_lastday'] not contained in axis"
          ]
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92ef46aab1bd0eba298d5eab61aa96188f79a891",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# test dataset\n## test x\nte_time = 24\nte_register_df = register_df[register_df.register_day<=te_time]\nte_x_df = te_register_df\n\n\n# register\n# register type --> (0,1,2,3)\nte_x_df[te_x_df.register_type>=3]['register_type'] = 3\n# register: device type --> (0,1,2,3)\ndevice_type_count = te_x_df['device_type'].value_counts()\ndef device_map(x):\n    if(device_type_count[x]>1500):\n        return 0\n    elif(device_type_count[x]>1000):\n        return 1\n    elif(device_type_count[x]>500):\n        return 2\n    else:\n        return 3\n\nte_device_type = te_x_df['device_type'].map(device_map)\nte_x_df['device_pop_type'] = te_device_type\n\n# launch\nte_launch_df = launch_df[launch_df.launch_day<=te_time]\n# launch_bool\nte_launch_uid = te_launch_df.user_id.unique()\nte_x_df['launch_bool'] = te_register_df.user_id.map(lambda x: x in te_launch_uid).map({False: 0, True:1})\n# launch num (ununique)\nte_launch_df_rmdup = te_launch_df.drop_duplicates()\nte_launch_num_df = te_launch_df.groupby('user_id').count().reset_index().rename(columns={'launch_day': 'launch_num'})\n# launch count(unique)\nte_launch_count_df = te_launch_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'launch_day': 'launch_count'})\n# launch ratio\nte_launch_ratio_df = pd.merge(te_register_df[['user_id', 'register_day']],te_launch_count_df, how='left', on='user_id' )\nte_x_df['launch_ratio'] = te_launch_ratio_df.launch_count/(te_time-te_launch_ratio_df.register_day+1)\n# launch first day interval\nte_launch_firstday_df = te_launch_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'launch_day': 'launch_firstday_interval'})\nte_launch_firstday_interval = te_launch_firstday_df['launch_firstday_interval']-te_register_df[te_x_df['launch_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\nte_launch_firstday_interval_df = pd.concat([te_launch_firstday_df.user_id, te_launch_firstday_interval], axis=1)\nte_launch_firstday_interval_df.columns=['user_id', 'launch_firstday_interval']\n# launch last day interval\nte_launch_lastday_df = te_launch_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'launch_day': 'launch_lastday_interval'})\nte_launch_lastday_interval = te_time-te_launch_lastday_df['launch_lastday_interval']\nte_launch_lastday_interval_df = pd.concat([te_launch_lastday_df.user_id, te_launch_lastday_interval], axis=1)\n# launch interval day(max)\nte_launch_df_sort = te_launch_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('launch_day', ascending=True)).reset_index(drop=True)\nte_launch_interval_df = pd.concat([te_launch_df_sort['user_id'], te_launch_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'launch_day': 'launch_interval_day'})\n\ndef fillna_te_launch_interval(df):\n    new_df = df\n    for idx, row in df.iterrows():\n        if(pd.isna(row.launch_interval_day)):\n            #print(te_launch_firstday_df[te_launch_firstday_df.user_id==row.user_id])\n            #print(te_launch_lastday_df[te_launch_lastday_df.user_id==row.user_id])\n            new_df.iloc[idx, 1] = max(int(te_launch_firstday_df[te_launch_firstday_df.user_id==row.user_id].launch_firstday_interval),\n                                      int(te_launch_lastday_df[te_launch_lastday_df.user_id==row.user_id].launch_lastday_interval))\n    return new_df\nte_launch_interval_df = fillna_te_launch_interval(te_launch_interval_df)\n\n# video \nte_video_df = video_df[video_df.create_day<=te_time]\n# video bool\nte_video_uid = te_video_df.user_id.unique()\nte_x_df['create_bool']= te_register_df.user_id.map(lambda x: x in te_video_uid).map({False: 0, True:1})\n# video num (ununique)\nte_video_df_rmdup = te_video_df.drop_duplicates()\nte_video_num_df = te_video_df.groupby('user_id').count().reset_index().rename(columns={'create_day': 'create_num'})\n# video count (unique)\nte_video_count_df = te_video_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'create_day': 'create_count'})\n# video ratio \nte_video_ratio_df = pd.merge(te_register_df[['user_id', 'register_day']],te_video_count_df, how='left', on='user_id' )\nte_x_df['create_ratio'] = te_video_ratio_df.create_count/(te_time-te_video_ratio_df.register_day+1)\n# video first day interval\nte_video_firstday_df = te_video_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'create_day': 'create_firstday_interval'})\nte_video_firstday_interval = te_video_firstday_df['create_firstday_interval']-te_register_df[te_x_df['create_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\nte_video_firstday_interval_df = pd.concat([te_video_firstday_df.user_id, te_video_firstday_interval], axis=1)\nte_video_firstday_interval_df.columns = ['user_id', 'create_firstday_interval']\n# video last day interval\nte_video_lastday_df = te_video_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'create_day': 'create_lastday_interval'})\nte_video_lastday_interval = te_time-te_video_lastday_df['create_lastday_interval']\nte_video_lastday_interval_df = pd.concat([te_video_lastday_df.user_id, te_video_lastday_interval], axis=1)\n# video interval day (max)\nte_video_df_sort = te_video_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('create_day', ascending=True)).reset_index(drop=True)\nte_video_interval_df = pd.concat([te_video_df_sort['user_id'], te_video_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'create_day': 'create_interval_day'})\n\ndef fillna_te_video_interval(df):\n    new_df = df\n    for idx, row in df.iterrows():\n        if(pd.isna(row.create_interval_day)):\n            new_df.iloc[idx, 1] = max(int(te_video_firstday_df[te_video_firstday_df.user_id==row.user_id].create_firstday_interval),\n                                      int(te_video_lastday_df[te_video_lastday_df.user_id==row.user_id].create_lastday_interval))\n    return new_df\nte_video_interval_df = fillna_te_video_interval(te_video_interval_df)\n\n# acitivity \nte_activity_df = activity_df[activity_df.activity_day<=te_time]\n# activity bool\nte_activity_uid = te_activity_df.user_id.unique()\nte_x_df['activity_bool']= te_register_df.user_id.apply(lambda x: x in te_activity_uid).map({False: 0, True:1})\n# acitivity num(ununique)\nte_activity_df_rmdup = te_activity_df[['user_id','activity_day']].drop_duplicates()\nte_activity_num_df = te_activity_df[['user_id','activity_day']].groupby('user_id').count().reset_index().rename(columns={'activity_day': 'activity_num'})\n# acitivity count(unique)\nte_activity_count_df = te_activity_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'activity_day': 'activity_count'})\n# activity ratio \nte_activity_ratio_df = pd.merge(te_register_df[['user_id', 'register_day']],te_activity_count_df, how='left', on='user_id' )\nte_x_df['activity_ratio'] = te_activity_ratio_df.activity_count/(te_time-te_activity_ratio_df.register_day+1)\n# activity first day interval\nte_activity_firstday_df = te_activity_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'activity_day': 'activity_firstday_interval'})\nte_activity_firstday_interval = te_activity_firstday_df['activity_firstday_interval']-te_register_df[te_x_df['activity_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\nte_activity_firstday_interval_df = pd.concat([te_activity_firstday_df.user_id, te_activity_firstday_interval], axis=1)\nte_activity_firstday_interval_df.columns = ['user_id', 'activity_firstday_interval']\n# activity last day interval\nte_activity_lastday_df = te_activity_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'activity_day': 'activity_lastday_interval'})\nte_activity_lastday_interval = te_time-te_activity_lastday_df['activity_lastday_interval']\nte_activity_lastday_interval_df = pd.concat([te_activity_lastday_df.user_id, te_activity_lastday_interval], axis=1)\n# activity interval day (max)\nte_activity_df_sort = te_activity_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('activity_day', ascending=True)).reset_index(drop=True)\nte_activity_interval_df = pd.concat([te_activity_df_sort['user_id'], te_activity_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'activity_day': 'activity_interval_day'})\n\ndef fillna_te_activity_interval(df):\n    new_df = df\n    for idx, row in df.iterrows():\n        if(pd.isna(row.activity_interval_day)):\n            new_df.iloc[idx, 1] = max(int(te_activity_firstday_df[te_activity_firstday_df.user_id==row.user_id].activity_firstday_interval),\n                                      int(te_activity_lastday_df[te_activity_lastday_df.user_id==row.user_id].activity_lastday_interval))\n    return new_df\nte_activity_interval_df = fillna_te_activity_interval(te_activity_interval_df)\n\n# merge register, video, activity\n\nte_x_df = pd.merge(te_x_df, te_launch_num_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_launch_count_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_launch_firstday_interval_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_launch_lastday_interval_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_launch_interval_df, how='left', on='user_id')\n\nte_x_df = pd.merge(te_x_df, te_video_num_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_video_count_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_video_firstday_interval_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_video_lastday_interval_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_video_interval_df, how='left', on='user_id')\n\nte_x_df = pd.merge(te_x_df, te_activity_num_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_activity_count_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_activity_firstday_interval_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_activity_lastday_interval_df, how='left', on='user_id')\nte_x_df = pd.merge(te_x_df, te_activity_interval_df, how='left', on='user_id')\n\nte_x_df[['launch_firstday_interval', 'launch_lastday_interval', 'launch_interval_day',]].fillna(te_time, inplace=True)\nte_x_df[['create_firstday_interval', 'create_lastday_interval', 'create_interval_day',]].fillna(te_time, inplace=True)\nte_x_df[['activity_firstday_interval', 'activity_lastday_interval', 'activity_interval_day']].fillna(te_time, inplace=True)\nte_x_df.fillna(0, inplace=True)\n\nte_x_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d7285fc55a3063ae42dba41519986f105f4da74",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# preprocess \ntr_x = np.asarray(tr_x_df)\nte_x = np.asarray(te_x_df)\n\n# Normalization\nfrom sklearn import preprocessing\nscaler_te = preprocessing.MinMaxScaler().fit(te_x)\nscaler_tr = preprocessing.MinMaxScaler().fit(tr_x)\nte_x_norm = scaler_te.transform(te_x)\ntr_x_norm = scaler_tr.transform(tr_x)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d35a449ec52de3b8dece29aa2072130662c5849",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9f485d7f4e3776c8bbbb67403790d6a60c9be51a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# loading classfiers\nnames = ['SVC', 'DTC', 'ABC', 'RFC', 'ETC', 'GBC', 'MLPC','KNC', 'LR', 'LDA']\nrandom_state = 1\nclassifiers = []\nclassifiers.append(SVC(random_state=random_state))\nclassifiers.append(DecisionTreeClassifier(random_state=random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),random_state=random_state,learning_rate=0.1))\nclassifiers.append(RandomForestClassifier(random_state=random_state))\nclassifiers.append(ExtraTreesClassifier(random_state=random_state))\nclassifiers.append(GradientBoostingClassifier(random_state=random_state))\nclassifiers.append(MLPClassifier(solver='sgd', alpha=1e-4,max_iter=500, batch_size=32,learning_rate_init=0.01, learning_rate= 'adaptive', hidden_layer_sizes=(10,5,2), random_state=random_state))\nclassifiers.append(KNeighborsClassifier())\nclassifiers.append(LogisticRegression(random_state=random_state))\nclassifiers.append(LinearDiscriminantAnalysis())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8c0694b97aed55dacd976c235bc2e26ff6507c41"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import GridSearchCV",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "43397395120d2d223c0f93705a2399928545c2f3",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# training model\nfor i in [6]:\n    clf = classifiers[i]\n    name = names[i]\n    clf.fit(tr_x_norm, tr_y)\n    prediction = clf.predict(te_x_norm)\n    results = pd.DataFrame(te_register_df['user_id'])\n    results['pred'] = prediction\n    actuser = results[results.pred==1].user_id.unique()\n    np.savetxt(name+'.v2.txt', actuser, fmt='%d')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "2efc37df11ebcd6a8ac43e0788b5e217c16f73f9"
      },
      "cell_type": "code",
      "source": "import xgboost as xgb",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2d7f2d1f607d9d9ebb4597647ae70b8bdb90a874",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "xgtrain = xgb.DMatrix(tr_x_norm, tr_y)\nxgtest = xgb.DMatrix(te_x_norm)\n# specify parameters via map\nparam = {'max_depth':10, 'n_estimators = 500', 'learning_rate' = 0.05, 'objective':'binary:logistic' }\nnum_round = 100\nbst = xgb.train(param, xgtrain, num_round)\n# make prediction\nxgb_preds = bst.predict(xgtest)\nresults = pd.DataFrame(te_register_df['user_id'])\nresults['pred'] = xgb_preds\nactuser = results[results.pred>0.5].user_id.unique()\nnp.savetxt('xgb.v2.txt', actuser, fmt='%d')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}