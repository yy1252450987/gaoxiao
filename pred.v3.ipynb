{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['video_create_log.txt', 'user_activity_log.txt', 'app_launch_log.txt', 'user_register_log.txt']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "register_df = pd.read_table('./input/user_register_log.txt',header=None, sep='\\t',\n",
    "                            names=['user_id','register_day','register_type','device_type'])\n",
    "launch_df = pd.read_table('./input/app_launch_log.txt', names=['user_id','launch_day'],header=None, sep='\\t')\n",
    "video_df = pd.read_table('./input/video_create_log.txt', names=['user_id','create_day'],header=None, sep='\\t')\n",
    "activity_df = pd.read_table('./input/user_activity_log.txt', header=None, sep='\\t',\n",
    "                            names=['user_id','activity_day','page','video_id','author_id','action_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "0e460e30b75ce8f99e20af936a7147fff6f1c98e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train dataset\n",
    "## train x\n",
    "tr_time = 24\n",
    "tr_register_df = register_df[register_df.register_day<=tr_time]\n",
    "tr_x_df = tr_register_df\n",
    "## train y\n",
    "tr_launch_uid = launch_df[launch_df.launch_day>tr_time].user_id.unique()\n",
    "tr_video_uid = video_df[video_df.create_day>tr_time].user_id.unique()\n",
    "tr_activity_uid = activity_df[activity_df.activity_day>tr_time].user_id.unique()\n",
    "tr_y = tr_register_df.user_id.map(lambda x: x in tr_launch_uid or x in tr_activity_uid or x in tr_video_uid ).map({False: 0, True:1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "97831e2c090f5aed6618a3ef86738983b156a683"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# register\n",
    "# register type --> (0,1,2,3)\n",
    "tr_x_df[tr_x_df.register_type>=3]['register_type'] = 3\n",
    "# register: device type --> (0,1,2,3)\n",
    "device_type_count = tr_x_df['device_type'].value_counts()\n",
    "def device_map(x):\n",
    "    if(device_type_count[x]>1500):\n",
    "        return 0\n",
    "    elif(device_type_count[x]>1000):\n",
    "        return 1\n",
    "    elif(device_type_count[x]>500):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "tr_device_type = tr_x_df['device_type'].map(device_map)\n",
    "tr_x_df['device_pop_type'] = tr_device_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6956ce93d8b1e1ecfafed8488e2c89947809857c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# launch\n",
    "tr_launch_df = launch_df[launch_df.launch_day<=tr_time]\n",
    "# launch_bool\n",
    "tr_launch_uid = tr_launch_df.user_id.unique()\n",
    "tr_x_df['launch_bool'] = tr_register_df.user_id.map(lambda x: x in tr_launch_uid).map({False: 0, True:1})\n",
    "# launch num (ununique)\n",
    "tr_launch_df_rmdup = tr_launch_df.drop_duplicates()\n",
    "tr_launch_num_df = tr_launch_df.groupby('user_id').count().reset_index().rename(columns={'launch_day': 'launch_num'})\n",
    "# launch count(unique)\n",
    "tr_launch_count_df = tr_launch_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'launch_day': 'launch_count'})\n",
    "# launch ratio\n",
    "tr_launch_ratio_df = pd.merge(tr_register_df[['user_id', 'register_day']],tr_launch_count_df, how='left', on='user_id' )\n",
    "tr_x_df['launch_ratio'] = tr_launch_ratio_df.launch_count/(tr_time-tr_launch_ratio_df.register_day+1)\n",
    "# launch first day interval\n",
    "tr_launch_firstday_df = tr_launch_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'launch_day': 'launch_firstday_interval'})\n",
    "tr_launch_firstday_interval = tr_launch_firstday_df['launch_firstday_interval']-tr_register_df[tr_x_df['launch_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\n",
    "tr_launch_firstday_interval_df = pd.concat([tr_launch_firstday_df.user_id, tr_launch_firstday_interval], axis=1)\n",
    "tr_launch_firstday_interval_df.columns=['user_id', 'launch_firstday_interval']\n",
    "# launch last day interval\n",
    "tr_launch_lastday_df = tr_launch_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'launch_day': 'launch_lastday_interval'})\n",
    "tr_launch_lastday_interval = tr_time-tr_launch_lastday_df['launch_lastday_interval']\n",
    "tr_launch_lastday_interval_df = pd.concat([tr_launch_lastday_df.user_id, tr_launch_lastday_interval], axis=1)\n",
    "# launch interval day(max)\n",
    "tr_launch_df_sort = tr_launch_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('launch_day', ascending=True)).reset_index(drop=True)\n",
    "tr_launch_interval_df = pd.concat([tr_launch_df_sort['user_id'], tr_launch_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'launch_day': 'launch_interval_day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "14eefe64fd3b42a4f2ad356cd14cede8f0c43b1d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillna_tr_launch_interval(df):\n",
    "    new_df = df\n",
    "    for idx, row in df.iterrows():\n",
    "        if(pd.isna(row.launch_interval_day)):\n",
    "            #print(tr_launch_firstday_df[tr_launch_firstday_df.user_id==row.user_id])\n",
    "            #print(tr_launch_lastday_df[tr_launch_lastday_df.user_id==row.user_id])\n",
    "            new_df.iloc[idx, 1] = max(int(tr_launch_firstday_df[tr_launch_firstday_df.user_id==row.user_id].launch_firstday_interval),\n",
    "                                      int(tr_launch_lastday_df[tr_launch_lastday_df.user_id==row.user_id].launch_lastday_interval))\n",
    "    return new_df\n",
    "tr_launch_interval_df = fillna_tr_launch_interval(tr_launch_interval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e3834891fd1a72e17297be08c167d6477a4dbdc2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# video \n",
    "tr_video_df = video_df[video_df.create_day<=tr_time]\n",
    "# video bool\n",
    "tr_video_uid = tr_video_df.user_id.unique()\n",
    "tr_x_df['create_bool']= tr_register_df.user_id.map(lambda x: x in tr_video_uid).map({False: 0, True:1})\n",
    "# video num (ununique)\n",
    "tr_video_df_rmdup = tr_video_df.drop_duplicates()\n",
    "tr_video_num_df = tr_video_df.groupby('user_id').count().reset_index().rename(columns={'create_day': 'create_num'})\n",
    "# video count (unique)\n",
    "tr_video_count_df = tr_video_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'create_day': 'create_count'})\n",
    "# video ratio \n",
    "tr_video_ratio_df = pd.merge(tr_register_df[['user_id', 'register_day']],tr_video_count_df, how='left', on='user_id' )\n",
    "tr_x_df['create_ratio'] = tr_video_ratio_df.create_count/(tr_time-tr_video_ratio_df.register_day+1)\n",
    "# video first day interval\n",
    "tr_video_firstday_df = tr_video_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'create_day': 'create_firstday_interval'})\n",
    "tr_video_firstday_interval = tr_video_firstday_df['create_firstday_interval']-tr_register_df[tr_x_df['create_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\n",
    "tr_video_firstday_interval_df = pd.concat([tr_video_firstday_df.user_id, tr_video_firstday_interval], axis=1)\n",
    "tr_video_firstday_interval_df.columns = ['user_id', 'create_firstday_interval']\n",
    "# video last day interval\n",
    "tr_video_lastday_df = tr_video_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'create_day': 'create_lastday_interval'})\n",
    "tr_video_lastday_interval = tr_time-tr_video_lastday_df['create_lastday_interval']\n",
    "tr_video_lastday_interval_df = pd.concat([tr_video_lastday_df.user_id, tr_video_lastday_interval], axis=1)\n",
    "# video interval day (max)\n",
    "tr_video_df_sort = tr_video_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('create_day', ascending=True)).reset_index(drop=True)\n",
    "tr_video_interval_df = pd.concat([tr_video_df_sort['user_id'], tr_video_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'create_day': 'create_interval_day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "964c5b630f8b894071189e86d0f36e89966feff4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillna_tr_video_interval(df):\n",
    "    new_df = df\n",
    "    for idx, row in df.iterrows():\n",
    "        if(pd.isna(row.create_interval_day)):\n",
    "            new_df.iloc[idx, 1] = max(int(tr_video_firstday_df[tr_video_firstday_df.user_id==row.user_id].create_firstday_interval),\n",
    "                                      int(tr_video_lastday_df[tr_video_lastday_df.user_id==row.user_id].create_lastday_interval))\n",
    "    return new_df\n",
    "tr_video_interval_df = fillna_tr_video_interval(tr_video_interval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "c876eaad3fba00ce44662668989d87ad91ea20d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# acitivity \n",
    "tr_activity_df = activity_df[activity_df.activity_day<=tr_time]\n",
    "# activity bool\n",
    "tr_activity_uid = tr_activity_df.user_id.unique()\n",
    "tr_x_df['activity_bool']= tr_register_df.user_id.apply(lambda x: x in tr_activity_uid).map({False: 0, True:1})\n",
    "# acitivity num(ununique)\n",
    "tr_activity_df_rmdup = tr_activity_df[['user_id','activity_day']].drop_duplicates()\n",
    "tr_activity_num_df = tr_activity_df[['user_id','activity_day']].groupby('user_id').count().reset_index().rename(columns={'activity_day': 'activity_num'})\n",
    "# acitivity count(unique)\n",
    "tr_activity_count_df = tr_activity_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'activity_day': 'activity_count'})\n",
    "# activity ratio \n",
    "tr_activity_ratio_df = pd.merge(tr_register_df[['user_id', 'register_day']],tr_activity_count_df, how='left', on='user_id' )\n",
    "tr_x_df['activity_ratio'] = tr_activity_ratio_df.activity_count/(tr_time-tr_activity_ratio_df.register_day+1)\n",
    "# activity first day interval\n",
    "tr_activity_firstday_df = tr_activity_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'activity_day': 'activity_firstday_interval'})\n",
    "tr_activity_firstday_interval = tr_activity_firstday_df['activity_firstday_interval']-tr_register_df[tr_x_df['activity_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\n",
    "tr_activity_firstday_interval_df = pd.concat([tr_activity_firstday_df.user_id, tr_activity_firstday_interval], axis=1)\n",
    "tr_activity_firstday_interval_df.columns = ['user_id', 'activity_firstday_interval']\n",
    "# activity last day interval\n",
    "tr_activity_lastday_df = tr_activity_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'activity_day': 'activity_lastday_interval'})\n",
    "tr_activity_lastday_interval = tr_time-tr_activity_lastday_df['activity_lastday_interval']\n",
    "tr_activity_lastday_interval_df = pd.concat([tr_activity_lastday_df.user_id, tr_activity_lastday_interval], axis=1)\n",
    "# activity interval day (max)\n",
    "tr_activity_df_sort = tr_activity_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('activity_day', ascending=True)).reset_index(drop=True)\n",
    "tr_activity_interval_df = pd.concat([tr_activity_df_sort['user_id'], tr_activity_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'activity_day': 'activity_interval_day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4e6239dcc1c19773a140c9b7c20115572c4326a1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fillna_tr_activity_interval(df):\n",
    "    new_df = df\n",
    "    for idx, row in df.iterrows():\n",
    "        if(pd.isna(row.activity_interval_day)):\n",
    "            new_df.iloc[idx, 1] = max(int(tr_activity_firstday_df[tr_activity_firstday_df.user_id==row.user_id].activity_firstday_interval),\n",
    "                                      int(tr_activity_lastday_df[tr_activity_lastday_df.user_id==row.user_id].activity_lastday_interval))\n",
    "    return new_df\n",
    "tr_activity_interval_df = fillna_tr_activity_interval(tr_activity_interval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "0d3d2e5a4b0d7a294dad2a1f38a163333ef25a62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>page_0</th>\n",
       "      <th>page_1</th>\n",
       "      <th>page_2</th>\n",
       "      <th>page_3</th>\n",
       "      <th>page_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.849515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.111650</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>0.969512</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.029133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>218</td>\n",
       "      <td>0.204461</td>\n",
       "      <td>0.211896</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>0.578686</td>\n",
       "      <td>0.003717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    page_0    page_1    page_2    page_3    page_4\n",
       "0       16  0.849515       NaN  0.038835  0.111650       NaN\n",
       "1       30  0.562500       NaN       NaN  0.437500       NaN\n",
       "2       98       NaN       NaN  1.000000       NaN       NaN\n",
       "3      105  0.969512  0.001355  0.029133       NaN       NaN\n",
       "4      218  0.204461  0.211896  0.001239  0.578686  0.003717"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_page_df = tr_activity_df[['user_id','page']]\n",
    "tr_page_df['bool'] = 1\n",
    "tr_new_page_df = tr_page_df.groupby(['user_id', 'page']).sum().reset_index()\n",
    "tr_page_dummies_df = pd.DataFrame(index=tr_new_page_df.user_id.unique())\n",
    "tr_x_page=(tr_page_df.groupby(['user_id', 'page']).sum()/tr_page_df.groupby(['user_id']).sum()).drop(['page'], axis=1).reset_index()\n",
    "for idx,row in tr_x_page.iterrows():\n",
    "    tr_page_dummies_df.loc[int(row.user_id), 'page_'+str(int(row.page))]=float(row['bool'])\n",
    "tr_page_dummies_df = tr_page_dummies_df[np.sort(np.asarray(tr_page_dummies_df.columns))]\n",
    "tr_page_dummies_df.reset_index(inplace=True)\n",
    "tr_page_dummies_df.rename(columns={'index':'user_id'},inplace=True)\n",
    "tr_page_dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "a63a1b76da3100c63a39d9380105d17549f3feff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>action_type_0</th>\n",
       "      <th>action_type_1</th>\n",
       "      <th>action_type_2</th>\n",
       "      <th>action_type_3</th>\n",
       "      <th>action_type_4</th>\n",
       "      <th>action_type_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.980583</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>0.927507</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.070461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>218</td>\n",
       "      <td>0.976456</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>0.018587</td>\n",
       "      <td>0.001239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  action_type_0  action_type_1  action_type_2  action_type_3  \\\n",
       "0       16       0.980583       0.009709       0.009709            NaN   \n",
       "1       30       0.964286       0.008929       0.026786            NaN   \n",
       "2       98       1.000000            NaN            NaN            NaN   \n",
       "3      105       0.927507       0.001355       0.000678       0.070461   \n",
       "4      218       0.976456       0.003717       0.018587       0.001239   \n",
       "\n",
       "   action_type_4  action_type_5  \n",
       "0            NaN            NaN  \n",
       "1            NaN            NaN  \n",
       "2            NaN            NaN  \n",
       "3            NaN            NaN  \n",
       "4            NaN            NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_action_type_df = tr_activity_df[['user_id','action_type']]\n",
    "tr_action_type_df['bool'] = 1\n",
    "tr_new_action_type_df = tr_action_type_df.groupby(['user_id', 'action_type']).sum().reset_index()\n",
    "tr_action_type_dummies_df = pd.DataFrame(index=tr_new_action_type_df.user_id.unique())\n",
    "tr_x_action_type=(tr_action_type_df.groupby(['user_id', 'action_type']).sum()/tr_action_type_df.groupby(['user_id']).sum()).drop(['action_type'], axis=1).reset_index()\n",
    "for idx,row in tr_x_action_type.iterrows():\n",
    "    tr_action_type_dummies_df.loc[int(row.user_id), 'action_type_'+str(int(row.action_type))]=float(row['bool'])\n",
    "tr_action_type_dummies_df = tr_action_type_dummies_df[np.sort(np.asarray(tr_action_type_dummies_df.columns))]\n",
    "tr_action_type_dummies_df.reset_index(inplace=True)\n",
    "tr_action_type_dummies_df.rename(columns={'index':'user_id'},inplace=True)\n",
    "tr_action_type_dummies_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "f987f693a01e2569cee9eee9e8525c9b6fa7e52e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>video_id_count</th>\n",
       "      <th>author_id_count</th>\n",
       "      <th>video_author_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>187</td>\n",
       "      <td>162</td>\n",
       "      <td>1.154321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>56</td>\n",
       "      <td>1.732143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105</td>\n",
       "      <td>1212</td>\n",
       "      <td>1015</td>\n",
       "      <td>1.194089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>218</td>\n",
       "      <td>633</td>\n",
       "      <td>149</td>\n",
       "      <td>4.248322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  video_id_count  author_id_count  video_author_ratio\n",
       "0       16             187              162            1.154321\n",
       "1       30              97               56            1.732143\n",
       "2       98               1                1            1.000000\n",
       "3      105            1212             1015            1.194089\n",
       "4      218             633              149            4.248322"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_author_id_df = tr_activity_df[['user_id', 'author_id']]\n",
    "tr_author_id_df_rmdup = tr_author_id_df[['user_id','author_id']].drop_duplicates()\n",
    "tr_author_id_count_df = tr_author_id_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'author_id': 'author_id_count'})\n",
    "\n",
    "tr_video_id_df = tr_activity_df[['user_id', 'video_id']]\n",
    "tr_video_id_df_rmdup = tr_video_id_df[['user_id','video_id']].drop_duplicates()\n",
    "tr_video_id_count_df = tr_video_id_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'video_id': 'video_id_count'})\n",
    "\n",
    "tr_video_author_id_df = pd.merge(tr_video_id_count_df,tr_author_id_count_df, how='left',on='user_id')\n",
    "tr_video_author_id_df['video_author_ratio'] = tr_video_author_id_df['video_id_count']/tr_video_author_id_df['author_id_count']\n",
    "tr_video_author_id_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "fdc8f4067a27b418db6d816a487ebb0973b36142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40518, 26)\n"
     ]
    }
   ],
   "source": [
    "# merge register, video, activity\n",
    "\n",
    "tr_x_df = pd.merge(tr_x_df, tr_launch_num_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_launch_count_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_launch_firstday_interval_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_launch_lastday_interval_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_launch_interval_df, how='left', on='user_id')\n",
    "\n",
    "tr_x_df = pd.merge(tr_x_df, tr_video_num_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_video_count_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_video_firstday_interval_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_video_lastday_interval_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_video_interval_df, how='left', on='user_id')\n",
    "\n",
    "tr_x_df = pd.merge(tr_x_df, tr_activity_num_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_activity_count_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_activity_firstday_interval_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_activity_lastday_interval_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_activity_interval_df, how='left', on='user_id')\n",
    "#print(tr_x_df.shape)\n",
    "tr_x_df = pd.merge(tr_x_df, tr_page_dummies_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_action_type_dummies_df, how='left', on='user_id')\n",
    "tr_x_df = pd.merge(tr_x_df, tr_video_author_id_df, how='left', on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "5f7a5839d516b1b2f9ae74acff82ee4b96662d2c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:3035: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tr_x_df[['launch_firstday_interval', 'launch_lastday_interval', 'launch_interval_day',]].fillna(tr_time, inplace=True)\n",
    "tr_x_df[['create_firstday_interval', 'create_lastday_interval', 'create_interval_day',]].fillna(tr_time, inplace=True)\n",
    "tr_x_df[['activity_firstday_interval', 'activity_lastday_interval', 'activity_interval_day']].fillna(tr_time, inplace=True)\n",
    "tr_x_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "578519569a438f0141bbe66d14614e2bfb9fc85d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>register_day</th>\n",
       "      <th>launch_bool</th>\n",
       "      <th>launch_ratio</th>\n",
       "      <th>create_bool</th>\n",
       "      <th>create_ratio</th>\n",
       "      <th>activity_bool</th>\n",
       "      <th>activity_ratio</th>\n",
       "      <th>launch_num</th>\n",
       "      <th>launch_count</th>\n",
       "      <th>launch_firstday_interval</th>\n",
       "      <th>...</th>\n",
       "      <th>register_type_6</th>\n",
       "      <th>register_type_7</th>\n",
       "      <th>register_type_8</th>\n",
       "      <th>register_type_9</th>\n",
       "      <th>register_type_10</th>\n",
       "      <th>register_type_11</th>\n",
       "      <th>device_pop_type_0</th>\n",
       "      <th>device_pop_type_1</th>\n",
       "      <th>device_pop_type_2</th>\n",
       "      <th>device_pop_type_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   register_day  launch_bool  launch_ratio  create_bool  create_ratio  \\\n",
       "0             1            1      0.125000            0           0.0   \n",
       "1             1            1      0.083333            0           0.0   \n",
       "2             1            1      0.250000            0           0.0   \n",
       "3             1            1      0.541667            0           0.0   \n",
       "4             1            1      0.416667            0           0.0   \n",
       "\n",
       "   activity_bool  activity_ratio  launch_num  launch_count  \\\n",
       "0              1        0.125000           3             3   \n",
       "1              1        0.083333           2             2   \n",
       "2              1        0.250000           6             6   \n",
       "3              1        0.333333          13            13   \n",
       "4              1        0.250000          10            10   \n",
       "\n",
       "   launch_firstday_interval        ...          register_type_6  \\\n",
       "0                         0        ...                        0   \n",
       "1                         0        ...                        0   \n",
       "2                         0        ...                        0   \n",
       "3                         0        ...                        0   \n",
       "4                         0        ...                        0   \n",
       "\n",
       "   register_type_7  register_type_8  register_type_9  register_type_10  \\\n",
       "0                0                0                0                 0   \n",
       "1                0                0                0                 0   \n",
       "2                0                0                0                 0   \n",
       "3                0                0                0                 0   \n",
       "4                0                0                0                 0   \n",
       "\n",
       "   register_type_11  device_pop_type_0  device_pop_type_1  device_pop_type_2  \\\n",
       "0                 0                  0                  0                  0   \n",
       "1                 0                  0                  0                  0   \n",
       "2                 0                  0                  1                  0   \n",
       "3                 0                  0                  0                  0   \n",
       "4                 0                  1                  0                  0   \n",
       "\n",
       "   device_pop_type_3  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill null value with 0 , get_dummie and drop columns\n",
    "#launch interval day (null value)\n",
    "tr_x_df = pd.concat([tr_x_df, pd.get_dummies(tr_x_df['register_type'], prefix='register_type')], axis=1)\n",
    "tr_x_df = pd.concat([tr_x_df, pd.get_dummies(tr_x_df['device_pop_type'], prefix='device_pop_type')], axis=1)\n",
    "#tr_x_df = pd.concat([tr_x_df, pd.get_dummies(tr_x_df['device_pop_type'], prefix='device_pop_type')], axis=1)\n",
    "tr_x_df = tr_x_df.drop(['user_id', 'device_type', 'device_pop_type','register_type'], axis=1)\n",
    "tr_x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "92ef46aab1bd0eba298d5eab61aa96188f79a891",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test dataset\n",
    "## test x\n",
    "te_time = 30\n",
    "te_register_df = register_df[register_df.register_day<=te_time]\n",
    "te_x_df = te_register_df\n",
    "\n",
    "\n",
    "# register\n",
    "# register type --> (0,1,2,3)\n",
    "te_x_df[te_x_df.register_type>=3]['register_type'] = 3\n",
    "# register: device type --> (0,1,2,3)\n",
    "device_type_count = te_x_df['device_type'].value_counts()\n",
    "def device_map(x):\n",
    "    if(device_type_count[x]>1500):\n",
    "        return 0\n",
    "    elif(device_type_count[x]>1000):\n",
    "        return 1\n",
    "    elif(device_type_count[x]>500):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "te_device_type = te_x_df['device_type'].map(device_map)\n",
    "te_x_df['device_pop_type'] = te_device_type\n",
    "\n",
    "# launch\n",
    "te_launch_df = launch_df[launch_df.launch_day<=te_time]\n",
    "# launch_bool\n",
    "te_launch_uid = te_launch_df.user_id.unique()\n",
    "te_x_df['launch_bool'] = te_register_df.user_id.map(lambda x: x in te_launch_uid).map({False: 0, True:1})\n",
    "# launch num (ununique)\n",
    "te_launch_df_rmdup = te_launch_df.drop_duplicates()\n",
    "te_launch_num_df = te_launch_df.groupby('user_id').count().reset_index().rename(columns={'launch_day': 'launch_num'})\n",
    "# launch count(unique)\n",
    "te_launch_count_df = te_launch_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'launch_day': 'launch_count'})\n",
    "# launch ratio\n",
    "te_launch_ratio_df = pd.merge(te_register_df[['user_id', 'register_day']],te_launch_count_df, how='left', on='user_id' )\n",
    "te_x_df['launch_ratio'] = te_launch_ratio_df.launch_count/(te_time-te_launch_ratio_df.register_day+1)\n",
    "# launch first day interval\n",
    "te_launch_firstday_df = te_launch_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'launch_day': 'launch_firstday_interval'})\n",
    "te_launch_firstday_interval = te_launch_firstday_df['launch_firstday_interval']-te_register_df[te_x_df['launch_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\n",
    "te_launch_firstday_interval_df = pd.concat([te_launch_firstday_df.user_id, te_launch_firstday_interval], axis=1)\n",
    "te_launch_firstday_interval_df.columns=['user_id', 'launch_firstday_interval']\n",
    "# launch last day interval\n",
    "te_launch_lastday_df = te_launch_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'launch_day': 'launch_lastday_interval'})\n",
    "te_launch_lastday_interval = te_time-te_launch_lastday_df['launch_lastday_interval']\n",
    "te_launch_lastday_interval_df = pd.concat([te_launch_lastday_df.user_id, te_launch_lastday_interval], axis=1)\n",
    "# launch interval day(max)\n",
    "te_launch_df_sort = te_launch_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('launch_day', ascending=True)).reset_index(drop=True)\n",
    "te_launch_interval_df = pd.concat([te_launch_df_sort['user_id'], te_launch_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'launch_day': 'launch_interval_day'})\n",
    "\n",
    "def fillna_te_launch_interval(df):\n",
    "    new_df = df\n",
    "    for idx, row in df.iterrows():\n",
    "        if(pd.isna(row.launch_interval_day)):\n",
    "            #print(te_launch_firstday_df[te_launch_firstday_df.user_id==row.user_id])\n",
    "            #print(te_launch_lastday_df[te_launch_lastday_df.user_id==row.user_id])\n",
    "            new_df.iloc[idx, 1] = max(int(te_launch_firstday_df[te_launch_firstday_df.user_id==row.user_id].launch_firstday_interval),\n",
    "                                      int(te_launch_lastday_df[te_launch_lastday_df.user_id==row.user_id].launch_lastday_interval))\n",
    "    return new_df\n",
    "te_launch_interval_df = fillna_te_launch_interval(te_launch_interval_df)\n",
    "\n",
    "# video \n",
    "te_video_df = video_df[video_df.create_day<=te_time]\n",
    "# video bool\n",
    "te_video_uid = te_video_df.user_id.unique()\n",
    "te_x_df['create_bool']= te_register_df.user_id.map(lambda x: x in te_video_uid).map({False: 0, True:1})\n",
    "# video num (ununique)\n",
    "te_video_df_rmdup = te_video_df.drop_duplicates()\n",
    "te_video_num_df = te_video_df.groupby('user_id').count().reset_index().rename(columns={'create_day': 'create_num'})\n",
    "# video count (unique)\n",
    "te_video_count_df = te_video_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'create_day': 'create_count'})\n",
    "# video ratio \n",
    "te_video_ratio_df = pd.merge(te_register_df[['user_id', 'register_day']],te_video_count_df, how='left', on='user_id' )\n",
    "te_x_df['create_ratio'] = te_video_ratio_df.create_count/(te_time-te_video_ratio_df.register_day+1)\n",
    "# video first day interval\n",
    "te_video_firstday_df = te_video_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'create_day': 'create_firstday_interval'})\n",
    "te_video_firstday_interval = te_video_firstday_df['create_firstday_interval']-te_register_df[te_x_df['create_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\n",
    "te_video_firstday_interval_df = pd.concat([te_video_firstday_df.user_id, te_video_firstday_interval], axis=1)\n",
    "te_video_firstday_interval_df.columns = ['user_id', 'create_firstday_interval']\n",
    "# video last day interval\n",
    "te_video_lastday_df = te_video_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'create_day': 'create_lastday_interval'})\n",
    "te_video_lastday_interval = te_time-te_video_lastday_df['create_lastday_interval']\n",
    "te_video_lastday_interval_df = pd.concat([te_video_lastday_df.user_id, te_video_lastday_interval], axis=1)\n",
    "# video interval day (max)\n",
    "te_video_df_sort = te_video_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('create_day', ascending=True)).reset_index(drop=True)\n",
    "te_video_interval_df = pd.concat([te_video_df_sort['user_id'], te_video_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'create_day': 'create_interval_day'})\n",
    "\n",
    "def fillna_te_video_interval(df):\n",
    "    new_df = df\n",
    "    for idx, row in df.iterrows():\n",
    "        if(pd.isna(row.create_interval_day)):\n",
    "            new_df.iloc[idx, 1] = max(int(te_video_firstday_df[te_video_firstday_df.user_id==row.user_id].create_firstday_interval),\n",
    "                                      int(te_video_lastday_df[te_video_lastday_df.user_id==row.user_id].create_lastday_interval))\n",
    "    return new_df\n",
    "te_video_interval_df = fillna_te_video_interval(te_video_interval_df)\n",
    "\n",
    "# acitivity \n",
    "te_activity_df = activity_df[activity_df.activity_day<=te_time]\n",
    "# activity bool\n",
    "te_activity_uid = te_activity_df.user_id.unique()\n",
    "te_x_df['activity_bool']= te_register_df.user_id.apply(lambda x: x in te_activity_uid).map({False: 0, True:1})\n",
    "# acitivity num(ununique)\n",
    "te_activity_df_rmdup = te_activity_df[['user_id','activity_day']].drop_duplicates()\n",
    "te_activity_num_df = te_activity_df[['user_id','activity_day']].groupby('user_id').count().reset_index().rename(columns={'activity_day': 'activity_num'})\n",
    "# acitivity count(unique)\n",
    "te_activity_count_df = te_activity_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'activity_day': 'activity_count'})\n",
    "# activity ratio \n",
    "te_activity_ratio_df = pd.merge(te_register_df[['user_id', 'register_day']],te_activity_count_df, how='left', on='user_id' )\n",
    "te_x_df['activity_ratio'] = te_activity_ratio_df.activity_count/(te_time-te_activity_ratio_df.register_day+1)\n",
    "# activity first day interval\n",
    "te_activity_firstday_df = te_activity_df_rmdup.groupby('user_id').min().reset_index().rename(columns={'activity_day': 'activity_firstday_interval'})\n",
    "te_activity_firstday_interval = te_activity_firstday_df['activity_firstday_interval']-te_register_df[te_x_df['activity_bool']==1].sort_values(by='user_id').register_day.reset_index(drop=True)\n",
    "te_activity_firstday_interval_df = pd.concat([te_activity_firstday_df.user_id, te_activity_firstday_interval], axis=1)\n",
    "te_activity_firstday_interval_df.columns = ['user_id', 'activity_firstday_interval']\n",
    "# activity last day interval\n",
    "te_activity_lastday_df = te_activity_df_rmdup.groupby('user_id').max().reset_index().rename(columns={'activity_day': 'activity_lastday_interval'})\n",
    "te_activity_lastday_interval = te_time-te_activity_lastday_df['activity_lastday_interval']\n",
    "te_activity_lastday_interval_df = pd.concat([te_activity_lastday_df.user_id, te_activity_lastday_interval], axis=1)\n",
    "# activity interval day (max)\n",
    "te_activity_df_sort = te_activity_df_rmdup.groupby('user_id').apply(lambda x: x.sort_values('activity_day', ascending=True)).reset_index(drop=True)\n",
    "te_activity_interval_df = pd.concat([te_activity_df_sort['user_id'], te_activity_df_sort.groupby('user_id').diff()], axis=1).groupby('user_id').max().reset_index().rename(columns={'activity_day': 'activity_interval_day'})\n",
    "\n",
    "def fillna_te_activity_interval(df):\n",
    "    new_df = df\n",
    "    for idx, row in df.iterrows():\n",
    "        if(pd.isna(row.activity_interval_day)):\n",
    "            new_df.iloc[idx, 1] = max(int(te_activity_firstday_df[te_activity_firstday_df.user_id==row.user_id].activity_firstday_interval),\n",
    "                                      int(te_activity_lastday_df[te_activity_lastday_df.user_id==row.user_id].activity_lastday_interval))\n",
    "    return new_df\n",
    "te_activity_interval_df = fillna_te_activity_interval(te_activity_interval_df)\n",
    "\n",
    "te_page_df = te_activity_df[['user_id','page']]\n",
    "te_page_df['bool'] = 1\n",
    "te_new_page_df = te_page_df.groupby(['user_id', 'page']).sum().reset_index()\n",
    "te_page_dummies_df = pd.DataFrame(index=te_new_page_df.user_id.unique())\n",
    "te_x_page=(te_page_df.groupby(['user_id', 'page']).sum()/te_page_df.groupby(['user_id']).sum()).drop(['page'], axis=1).reset_index()\n",
    "for idx,row in te_x_page.iterrows():\n",
    "    te_page_dummies_df.loc[int(row.user_id), 'page_'+str(int(row.page))]=float(row['bool'])\n",
    "te_page_dummies_df = te_page_dummies_df[np.sort(np.asarray(te_page_dummies_df.columns))]\n",
    "te_page_dummies_df.reset_index(inplace=True)\n",
    "te_page_dummies_df.rename(columns={'index':'user_id'},inplace=True)\n",
    "#te_page_dummies_df.head()\n",
    "\n",
    "te_action_type_df = te_activity_df[['user_id','action_type']]\n",
    "te_action_type_df['bool'] = 1\n",
    "te_new_action_type_df = te_action_type_df.groupby(['user_id', 'action_type']).sum().reset_index()\n",
    "te_action_type_dummies_df = pd.DataFrame(index=te_new_action_type_df.user_id.unique())\n",
    "te_x_action_type=(te_action_type_df.groupby(['user_id', 'action_type']).sum()/te_action_type_df.groupby(['user_id']).sum()).drop(['action_type'], axis=1).reset_index()\n",
    "for idx,row in te_x_action_type.iterrows():\n",
    "    te_action_type_dummies_df.loc[int(row.user_id), 'action_type_'+str(int(row.action_type))]=float(row['bool'])\n",
    "te_action_type_dummies_df = te_action_type_dummies_df[np.sort(np.asarray(te_action_type_dummies_df.columns))]\n",
    "te_action_type_dummies_df.reset_index(inplace=True)\n",
    "te_action_type_dummies_df.rename(columns={'index':'user_id'},inplace=True)\n",
    "#te_action_type_dummies_df.head()\n",
    "\n",
    "te_author_id_df = te_activity_df[['user_id', 'author_id']]\n",
    "te_author_id_df_rmdup = te_author_id_df[['user_id','author_id']].drop_duplicates()\n",
    "te_author_id_count_df = te_author_id_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'author_id': 'author_id_count'})\n",
    "\n",
    "te_video_id_df = te_activity_df[['user_id', 'video_id']]\n",
    "te_video_id_df_rmdup = te_video_id_df[['user_id','video_id']].drop_duplicates()\n",
    "te_video_id_count_df = te_video_id_df_rmdup.groupby('user_id').count().reset_index().rename(columns={'video_id': 'video_id_count'})\n",
    "\n",
    "te_video_author_id_df = pd.merge(te_video_id_count_df,te_author_id_count_df, how='left',on='user_id')\n",
    "te_video_author_id_df['video_author_ratio'] = te_video_author_id_df['video_id_count']/te_video_author_id_df['author_id_count']\n",
    "#te_video_author_id_df.head()\n",
    "\n",
    "\n",
    "# merge register, video, activity\n",
    "\n",
    "te_x_df = pd.merge(te_x_df, te_launch_num_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_launch_count_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_launch_firstday_interval_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_launch_lastday_interval_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_launch_interval_df, how='left', on='user_id')\n",
    "\n",
    "te_x_df = pd.merge(te_x_df, te_video_num_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_video_count_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_video_firstday_interval_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_video_lastday_interval_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_video_interval_df, how='left', on='user_id')\n",
    "\n",
    "te_x_df = pd.merge(te_x_df, te_activity_num_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_activity_count_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_activity_firstday_interval_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_activity_lastday_interval_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_activity_interval_df, how='left', on='user_id')\n",
    "\n",
    "te_x_df = pd.merge(te_x_df, te_page_dummies_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_action_type_dummies_df, how='left', on='user_id')\n",
    "te_x_df = pd.merge(te_x_df, te_video_author_id_df, how='left', on='user_id')\n",
    "\n",
    "te_x_df[['launch_firstday_interval', 'launch_lastday_interval', 'launch_interval_day',]].fillna(te_time, inplace=True)\n",
    "te_x_df[['create_firstday_interval', 'create_lastday_interval', 'create_interval_day',]].fillna(te_time, inplace=True)\n",
    "te_x_df[['activity_firstday_interval', 'activity_lastday_interval', 'activity_interval_day']].fillna(te_time, inplace=True)\n",
    "te_x_df.fillna(0, inplace=True)\n",
    "\n",
    "# fill null value with 0 , get_dummie and drop columns\n",
    "#launch interval day (null value)\n",
    "te_x_df = pd.concat([te_x_df, pd.get_dummies(te_x_df['register_type'], prefix='register_type')], axis=1)\n",
    "te_x_df = pd.concat([te_x_df, pd.get_dummies(te_x_df['device_pop_type'], prefix='device_pop_type')], axis=1)\n",
    "te_x_df = te_x_df.drop(['user_id', 'device_type', 'device_pop_type','register_type'], axis=1)\n",
    "te_x_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5d7285fc55a3063ae42dba41519986f105f4da74",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess \n",
    "tr_x = np.asarray(tr_x_df)\n",
    "te_x = np.asarray(te_x_df)\n",
    "\n",
    "# Normalization\n",
    "from sklearn import preprocessing\n",
    "std_scaler_te = preprocessing.StandardScaler().fit(te_x)\n",
    "std_scaler_tr = preprocessing.StandardScaler().fit(tr_x)\n",
    "std_te_x_norm = std_scaler_te.transform(te_x)\n",
    "std_tr_x_norm = std_scaler_tr.transform(tr_x)\n",
    "\n",
    "#minmax_scaler_te = preprocessing.MinMaxScaler().fit(te_x)\n",
    "#minmax_scaler_tr = preprocessing.MinMaxScaler().fit(tr_x)\n",
    "#minmax_te_x_norm = std_scaler_te.transform(te_x)\n",
    "#minmax_tr_x_norm = std_scaler_tr.transform(tr_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2efc37df11ebcd6a8ac43e0788b5e217c16f73f9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2d7f2d1f607d9d9ebb4597647ae70b8bdb90a874",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgtrain = xgb.DMatrix(tr_x_norm, tr_y)\n",
    "xgtest = xgb.DMatrix(te_x_norm)\n",
    "# specify parameters via map\n",
    "param = {'max_depth':10, 'n_estimators = 500', 'learning_rate' = 0.05, 'objective':'binary:logistic' }\n",
    "num_round = 100\n",
    "bst = xgb.train(param, xgtrain, num_round)\n",
    "# make prediction\n",
    "xgb_preds = bst.predict(xgtest)\n",
    "results = pd.DataFrame(te_register_df['user_id'])\n",
    "results['pred'] = xgb_preds\n",
    "actuser = results[results.pred>0.5].user_id.unique()\n",
    "np.savetxt('xgb.v3.txt', actuser, fmt='%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
