# 感悟 记录第一次打比赛之后的感想
## 心态
1. 这里的所有言论不是针对任何人，只是发表出我的一些想法和看法，大家可以互相讨论。
2. 大佬的心态过于乐观，我的心态过于悲观。属于两个极端，应该折中一下。
3. 比赛第二，收获第一。至少这次的挫败感让我又继续学下去的勇气，觉得自己还是很多不懂不会。

## 技术
1. 特征工程，特征工程，特征工程，重要的事情说三遍。
这次比赛没有说谁的特征工程的结果一定好，谁的特征工程一定坏，只是在测试集上的表现的好，我们才称之为好，换一套测试集结果可能完全不一样(AB榜)

2. 特征选择，这个本属于特征工程的一部分，这里单独拿出来讲。
是因为我们虽然创造了200多个特征，但是如何对其有效的筛选并不明确，学艺不精。
一些冗余的特征和无用的的特征的加入会导致模型效果变差。对于这次几万个样本的数据，我觉得最好的特征数目应该在几十个左右。

3. 这次比赛遇到的一个疑问就是在fine-tuning阶段，是做完特征选择在fine-tuning还是先fine-tuning在特征选择。
其实，打比赛的时候，我选择了后者，理论上前者更可靠。特征选择完之后可以基于baseline的结果选择是否要进行fine-tuning。

4. 树模型进行fine-tuning时，如何控制过拟合的问题。这次比赛的fine-tuningCV结果有些都是0.85级别的，但线上结果却只有0.813左右，过拟合十分严重。
我认为调参还是需要一些经验性的东西进行指导，n_estimator控制100以内最好（至少线上结果是这样的）。
对于lightgbm和xgboost有正则化的参数，可以防止过拟合，我认为它只是在一定程度上缓解过拟合，
1000棵树再怎么正则化也会过拟合，至少这次比赛结果是这样的。


## 策略
1. 先合并特征再各自建模还是先各自建模再合并？我现在的想法偏向于后者。有一下几点理由：
* 先融合了特征再进行建模，其实模型之间的差异并不是十分明显，特别是GBC,lghtGBM,XGboost预测结果都一样，各自建模再融合模型没有太大意义。
* 先融合特征虽然特征多，当给特征工程提出了更高的要求，因为我知道我的特征有一个baseline结果，而大佬的是没有baseline结果的，大佬的特征虽然多，
但是我们不知道哪些特征是有效的，理论上有个baseline结果会很有指导意义。
* 若各自做完特征工程的话，再建模的话，我们可以利用自己的baseline的结果来判断各自特征工程的好坏，这样是否需要进行模型融合，可以再进行判断。

2. Stacking技术的使用，还是和前面的想法一样，stacking提升模型性能的基础应该是模型之间的差异性足够明显以及模型的表现力都很好。
这里我们的模型整合时，如果模型表现一个好一个差或者都很差，再进行stacking其实也就没什么提升效果了。
这里我接一口锅MLP进行fine-tuning的时候，时间过长没能及时提交结果。

3. 比赛时间安排，我们由于各自原因再拿到最好前50时，就膨胀了，就开始划水了，导致a榜的排名一直下降，即使大佬后面加特征也没有很好的改善。
所以这口锅大家要一起背着。b榜的安排现在想想有点问题，首先我们首先应该交一个baseline结果，就可以大致知道我们特征的好坏了，然后再选择应变策略。
而不是直接进行fine-tuning提交不同模型的结果。属于第一次AB榜比赛没啥经验。

4. 整个比赛的流程策略不是特别明确，理论上打比赛的套路都是一样的，我们在比赛的时候属于摸着石头过河，没有一个前瞻性的策略。
说明我们看的kaggle还不是很多，看的都是一些入门级的kenerl，应该多看看大牛的kaggle思路，学习他们的思路，有个自己的流程图。


## 收获

1. 第一次参加正式比赛，意义重大。以前也就在kaggle看看别人的入门级kernal，学习学习。
这次第一次参加比赛，让自己知道有些东西看着简单实践起来却很难。

2. 深刻了解到自己很菜，菜的抠脚。身为研二的学生比不过本科的学生会很有愧疚感，让自己觉得不应该自甘堕落下去，觉得要学的东西还有很多。

3. 不管结果如何，大家都努力过，虽然有些失落，但是吸取教训远比比赛本身重要。

4. 最后，谢谢阿姨和大佬一个月来的辛苦付出，接下来我们还是要继续kaggle起来，而且好像还有另外一个比赛。

———— 生命不息，学习不止

